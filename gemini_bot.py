import io

import requests
import telebot
from dotenv import load_dotenv
from google import genai
from google.genai import types as genai_types
from google.genai.types import GenerateContentConfig, GoogleSearch, Tool
from PIL import Image

from constants import (
    COMMAND_LIST,
    DEFAULT_MODEL,
    GEMINI_API_KEY,
    PRO_CODE,
    GREETING_MESSAGE_TEMPLATE,
    MAX_FILE_SIZE_MB,
    QUICK_TOOLS_CONFIG,
    SEND_MODE_IMMEDIATE,
    SEND_MODE_MANUAL,
    SUPPORTED_MIME_TYPES,
    TELEGRAM_TOKEN,
    HELP_TEXT_TEMPLATE,
    get_model_alias,
    is_image_generation_model,
)

from keyboards import (
    get_file_download_keyboard,
    get_main_keyboard,
    get_model_selection_keyboard,
)
from functools import wraps

from utils import markdown_to_text, split_long_message


load_dotenv()

client = genai.Client(api_key=GEMINI_API_KEY)
bot = telebot.TeleBot(TELEGRAM_TOKEN)

bot.set_my_commands(COMMAND_LIST)


user_chats = {}
user_models = {}
user_last_responses = {}
user_send_modes = {}
user_message_buffer = {}
user_files_context = {}
user_search_enabled = {}

WHITELIST_FILE = "whitelist.txt"
whitelisted_users = set()


def load_whitelist():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ñ–∞–π–ª–∞"""
    try:
        with open(WHITELIST_FILE, "r") as f:
            for line in f:
                user_id = line.strip()
                if user_id:
                    whitelisted_users.add(int(user_id))
        print(f"Loaded {len(whitelisted_users)} users into whitelist.")
    except FileNotFoundError:
        print(
            f"Whitelist file '{WHITELIST_FILE}' not found. Starting with empty whitelist."
        )
    except Exception as e:
        print(f"Error loading whitelist: {e}")


def add_to_whitelist(user_id):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫."""
    if user_id not in whitelisted_users:
        try:
            with open(WHITELIST_FILE, "a") as f:
                f.write(f"{user_id}\n")
            whitelisted_users.add(user_id)
            print(f"Added user {user_id} to whitelist.")
        except Exception as e:
            print(f"Error adding user {user_id} to whitelist: {e}")


def is_whitelisted(user_id):
    """Checks if a user ID is in the whitelist."""

    return user_id in whitelisted_users


def ensure_user_started(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—á–∞–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–∏–∞–ª–æ–≥ –∫–æ–º–∞–Ω–¥–æ–π /start."""

    @wraps(func)
    def wrapper(message, *args, **kwargs):
        if isinstance(message, telebot.types.CallbackQuery):
            user_id = message.from_user.id
            chat_id = message.message.chat.id
            is_callback = True
        elif isinstance(message, telebot.types.Message):
            user_id = message.from_user.id
            chat_id = message.chat.id
            is_callback = False
        else:

            print(
                f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: ensure_user_started –ø–æ–ª—É—á–∏–ª –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø: {type(message)}"
            )
            return func(message, *args, **kwargs)

        if user_id not in user_models:
            try:
                if is_callback:
                    bot.answer_callback_query(message.id)
                bot.send_message(
                    chat_id,
                    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.",
                    reply_markup=telebot.types.ReplyKeyboardRemove(),
                )
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è '–≤–≤–µ–¥–∏—Ç–µ /start': {e}")
            return None
        return func(message, *args, **kwargs)

    return wrapper


def download_telegram_image(file_id):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Telegram."""
    file_info = bot.get_file(file_id)
    file_url = f"https://api.telegram.org/file/bot{TELEGRAM_TOKEN}/{file_info.file_path}"
    response = requests.get(file_url)
    return io.BytesIO(response.content)


def send_text_as_file(chat_id, text, filename="response.txt"):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–≤–µ—Ç –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞."""
    file_obj = io.BytesIO(text.encode("utf-8"))
    bot.send_document(
        chat_id,
        file_obj,
        caption="–í–∞—à –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç",
        visible_file_name=filename,
    )


def send_gemini_response_with_images(
    chat_id, response, reply_to_message_id=None
):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –æ—Ç–≤–µ—Ç Gemini, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∫–∞–∫ —Ç–µ–∫—Å—Ç, —Ç–∞–∫ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    text_parts = []

    if hasattr(response, "candidates") and response.candidates:
        for candidate in response.candidates:
            if hasattr(candidate, "content") and candidate.content:
                if (
                    hasattr(candidate.content, "parts")
                    and candidate.content.parts
                ):
                    for part in candidate.content.parts:
                        if hasattr(part, "text") and part.text:
                            text_parts.append(part.text)
                        elif hasattr(part, "inline_data"):
                            try:
                                image_data = part.inline_data.data
                                mime_type = part.inline_data.mime_type

                                image_bytes = io.BytesIO(image_data)

                                if mime_type.startswith("image/"):
                                    bot.send_photo(
                                        chat_id,
                                        image_bytes,
                                        reply_to_message_id=reply_to_message_id,
                                    )
                                else:
                                    bot.send_document(
                                        chat_id,
                                        image_bytes,
                                        visible_file_name=f"generated_content.{mime_type.split('/')[-1]}",
                                        reply_to_message_id=reply_to_message_id,
                                    )
                            except Exception as e:
                                print(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                                text_parts.append(
                                    f"[–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}]"
                                )

    if not text_parts and hasattr(response, "text") and response.text:
        text_parts.append(response.text)

    if text_parts:
        combined_text = "\n".join(text_parts)
        plain_text = markdown_to_text(combined_text)
        message_parts = split_long_message(plain_text)

        for i, part in enumerate(message_parts):
            bot.send_message(
                chat_id,
                part,
                reply_to_message_id=reply_to_message_id if i == 0 else None,
            )

        return combined_text

    return ""


@bot.message_handler(commands=["help"])
def handle_help_command(message):
    """–í—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å–ø—Ä–∞–≤–∫—É –ø–æ —Ñ—É–Ω–∫—Ü–∏—è–º –±–æ—Ç–∞."""
    help_text = HELP_TEXT_TEMPLATE.format(
        MAX_FILE_SIZE_MB=MAX_FILE_SIZE_MB,
        SEND_MODE_IMMEDIATE=SEND_MODE_IMMEDIATE,
        SEND_MODE_MANUAL=SEND_MODE_MANUAL,
    )

    for command_info in COMMAND_LIST:
        if command_info.command not in ["/start"]:
            example = ""
            if command_info.command == "/translate":
                example = " (–Ω–∞–ø—Ä. `/translate –ø—Ä–∏–≤–µ—Ç –º–∏—Ä`)"
            elif command_info.command == "/prompt":
                example = " (–Ω–∞–ø—Ä. `/prompt –Ω–∞–ø–∏—à–∏ —Å—Ç–∏—Ö`)"
            help_text += f"- *{command_info.command}*: {command_info.description}{example}\n"
    help_text += "- *–ü—Ä–∏–º–µ—Ä:* `/translate Hello world`\n"

    bot.send_message(message.chat.id, help_text, parse_mode="Markdown")


@bot.message_handler(commands=["unlock_pro"])
@ensure_user_started
def handle_unlock_pro(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /unlock_pro."""
    user_id = message.from_user.id
    command_parts = message.text.split(" ", 1)

    if len(command_parts) == 2 and command_parts[1].strip() == str(PRO_CODE):
        add_to_whitelist(user_id)
        bot.reply_to(message, "‚úÖ –î–æ—Å—Ç—É–ø –∫ –ø—Ä–æ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω!")
    else:
        bot.reply_to(message, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –∫–æ–¥. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π")


@bot.message_handler(commands=["start"])
def send_welcome(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /start."""
    user_id = message.from_user.id
    user_models[user_id] = DEFAULT_MODEL
    user_chats[user_id] = client.chats.create(model=user_models[user_id])
    user_last_responses[user_id] = None
    user_send_modes[user_id] = SEND_MODE_IMMEDIATE
    user_message_buffer[user_id] = []
    user_files_context[user_id] = []
    user_search_enabled[user_id] = True

    search_enabled = user_search_enabled[user_id]
    current_model = user_models[user_id]
    search_status_text = "–í–∫–ª ‚úÖ" if search_enabled else "–í—ã–∫–ª ‚ùå"

    greeting_text = GREETING_MESSAGE_TEMPLATE.format(
        model_name=get_model_alias(current_model),
        send_mode=user_send_modes[user_id],
        search_status=search_status_text,
        send_mode_immediate=SEND_MODE_IMMEDIATE,
        send_mode_manual=SEND_MODE_MANUAL,
    )

    bot.send_message(
        message.chat.id,
        greeting_text,
        reply_markup=get_main_keyboard(
            user_id, user_send_modes, search_enabled, current_model
        ),
        parse_mode="Markdown",
    )


@bot.message_handler(func=lambda message: message.text == "–ù–æ–≤—ã–π —á–∞—Ç")
@ensure_user_started
def new_chat(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ "–ù–æ–≤—ã–π —á–∞—Ç"."""
    user_id = message.from_user.id

    user_chats[user_id] = client.chats.create(model=user_models[user_id])
    user_last_responses[user_id] = None
    user_files_context[user_id] = []
    user_message_buffer[user_id] = []
    user_search_enabled[user_id] = user_search_enabled.get(user_id, False)

    current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)
    search_enabled = user_search_enabled[user_id]
    current_model = user_models[user_id]
    search_status = "–í–∫–ª ‚úÖ" if search_enabled else "–í—ã–∫–ª ‚ùå"

    bot.send_message(
        message.chat.id,
        f"–ù–∞—á–∞—Ç –Ω–æ–≤—ã–π —á–∞—Ç. –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω.\n\n"
        f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {get_model_alias(current_model)}\n"
        f"–†–µ–∂–∏–º –æ—Ç–ø—Ä–∞–≤–∫–∏: {current_mode}\n"
        f"–ü–æ–∏—Å–∫ Google: {search_status}",
        reply_markup=get_main_keyboard(
            user_id, user_send_modes, search_enabled, current_model
        ),
    )


@bot.message_handler(
    func=lambda message: message.text.startswith("–ü–æ–ª—É—á–∏—Ç—å .")
)
@ensure_user_started
def get_response_as_md(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ "–ü–æ–ª—É—á–∏—Ç—å .md üìÑ"."""
    user_id = message.from_user.id

    if user_last_responses.get(user_id):
        words = user_last_responses[user_id].split()
        filename = (
            "_".join(words[:3]) + ".md" if len(words) > 0 else "response.md"
        )
        filename = (
            filename.replace("/", "_").replace("\\", "_").replace(":", "_")
        )

        send_text_as_file(
            message.chat.id,
            user_last_responses[user_id],
            filename,
        )
    else:
        search_enabled = user_search_enabled.get(user_id, False)
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        bot.send_message(
            message.chat.id,
            "–£ –º–µ–Ω—è –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞.",
            reply_markup=get_main_keyboard(
                user_id, user_send_modes, search_enabled, current_model
            ),
        )


@bot.message_handler(func=lambda message: message.text.startswith("–†–µ–∂–∏–º:"))
@ensure_user_started
def handle_send_mode(message):
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π."""
    user_id = message.from_user.id
    chat_id = message.chat.id

    current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)

    new_mode = (
        SEND_MODE_MANUAL
        if current_mode == SEND_MODE_IMMEDIATE
        else SEND_MODE_IMMEDIATE
    )

    user_send_modes[user_id] = new_mode

    user_message_buffer[user_id] = []

    mode_message = f"–†–µ–∂–∏–º –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: *{new_mode}*\n\n"
    if new_mode == SEND_MODE_MANUAL:
        mode_message += "–¢–µ–ø–µ—Ä—å –≤–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –±—É–¥—É—Ç –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å—Å—è. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É '–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å—ë', —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏—Ö –≤ Gemini."
    else:
        mode_message += (
            "–¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–æ–µ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±—É–¥–µ—Ç —Å—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è –≤ Gemini."
        )

    search_enabled = user_search_enabled.get(user_id, False)
    current_model = user_models.get(user_id, DEFAULT_MODEL)
    bot.send_message(
        chat_id,
        mode_message,
        reply_markup=get_main_keyboard(
            user_id, user_send_modes, search_enabled, current_model
        ),
        parse_mode="Markdown",
    )


@bot.message_handler(func=lambda message: message.text.startswith("–ü–æ–∏—Å–∫:"))
@ensure_user_started
def handle_search_command(message):
    """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ Google."""
    user_id = message.from_user.id

    user_search_enabled[user_id] = not user_search_enabled[user_id]

    search_enabled = user_search_enabled[user_id]
    current_model = user_models.get(user_id, DEFAULT_MODEL)
    search_status = "–í–∫–ª ‚úÖ" if search_enabled else "–í—ã–∫–ª ‚ùå"
    bot.reply_to(
        message,
        f"üîé –ü–æ–∏—Å–∫ Google —Ç–µ–ø–µ—Ä—å: *{search_status}*",
        parse_mode="Markdown",
        reply_markup=get_main_keyboard(
            user_id, user_send_modes, search_enabled, current_model
        ),
    )


@bot.message_handler(func=lambda message: message.text.startswith("–ú–æ–¥–µ–ª—å:"))
@ensure_user_started
def select_model(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ "–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å"."""
    bot.send_message(
        message.chat.id,
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å Gemini:",
        reply_markup=get_model_selection_keyboard(),
    )


@bot.message_handler(func=lambda message: message.text == "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å—ë")
@ensure_user_started
def handle_send_all(message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (—Ç–µ–∫—Å—Ç –∏ —Ñ–æ—Ç–æ) –∏–∑ –±—É—Ñ–µ—Ä–∞, —Å–æ—Ö—Ä–∞–Ω—è—è —Ä–∞–∑—Ä—ã–≤—ã –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–∞–º–∏."""
    user_id = message.from_user.id
    chat_id = message.chat.id

    current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)
    if current_mode != SEND_MODE_MANUAL:
        search_enabled = user_search_enabled.get(user_id, False)
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        bot.reply_to(
            message,
            f"–≠—Ç–∞ –∫–Ω–æ–ø–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ '{SEND_MODE_MANUAL}'. "
            f"–í–∞—à —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: '{current_mode}'. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /send_mode.",
            reply_markup=get_main_keyboard(
                user_id, user_send_modes, search_enabled, current_model
            ),
        )
        return

    buffered_items = user_message_buffer.get(user_id, [])

    if not buffered_items:
        search_enabled = user_search_enabled.get(user_id, False)
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        bot.reply_to(
            message,
            "–ë—É—Ñ–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏–π –ø—É—Å—Ç. –ù–µ—á–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å.",
            reply_markup=get_main_keyboard(
                user_id, user_send_modes, search_enabled, current_model
            ),
        )
        return

    if user_id not in user_chats:
        search_enabled = user_search_enabled.get(user_id, False)
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        bot.reply_to(
            message,
            "–û—à–∏–±–∫–∞: —Å–µ—Å—Å–∏—è —á–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –Ω–æ–≤—ã–π —á–∞—Ç.",
            reply_markup=get_main_keyboard(
                user_id, user_send_modes, search_enabled, current_model
            ),
        )
        user_message_buffer[user_id] = []
        return

    combined_parts = []
    current_text_block = ""

    for item in buffered_items:
        if item["type"] == "text":

            if current_text_block:
                current_text_block += "\n\n" + item["content"]
            else:

                current_text_block = item["content"]
        elif item["type"] == "photo":

            if current_text_block:
                combined_parts.append(current_text_block)
                current_text_block = ""

            if item.get("caption"):
                combined_parts.append(item["caption"])
            combined_parts.append(item["image"])
        elif item["type"] == "document":
            if current_text_block:
                combined_parts.append(current_text_block)
                current_text_block = ""
            if item.get("caption"):
                combined_parts.append(item["caption"])
            try:
                combined_parts.append(
                    genai_types.Part.from_bytes(
                        mime_type=item["mime_type"], data=item["data"]
                    )
                )

                combined_parts.append(f"(–§–∞–π–ª: {item['filename']})")
            except Exception as file_err:
                bot.send_message(
                    chat_id,
                    f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª '{item['filename']}' –∏–∑ –±—É—Ñ–µ—Ä–∞ –≤ –∑–∞–ø—Ä–æ—Å: {file_err}",
                )

                continue

    if current_text_block:
        combined_parts.append(current_text_block)

    if not combined_parts:
        search_enabled = user_search_enabled.get(user_id, False)
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        bot.reply_to(
            message,
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑ –±—É—Ñ–µ—Ä–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–Ω –ø—É—Å—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –ø—É—Å—Ç—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã).",
            reply_markup=get_main_keyboard(
                user_id, user_send_modes, search_enabled, current_model
            ),
        )
        user_message_buffer[user_id] = []
        return

    bot.send_chat_action(chat_id, "typing")
    status_msg = bot.reply_to(
        message, "–û—Ç–ø—Ä–∞–≤–ª—è—é –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Ñ–æ—Ç–æ –≤ Gemini..."
    )

    try:
        current_model = user_models.get(user_id, DEFAULT_MODEL)
        if is_image_generation_model(current_model):
            gemini_config = GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"]
            )
        else:
            tools = [Tool(url_context=genai_types.UrlContext())]
            if user_search_enabled.get(user_id, False):
                tools.append(Tool(google_search=GoogleSearch()))
            gemini_config = GenerateContentConfig(tools=tools)

        response = user_chats[user_id].send_message(
            message=combined_parts, config=gemini_config
        )

        current_model = user_models.get(user_id, DEFAULT_MODEL)
        if is_image_generation_model(current_model):
            raw_response_text = send_gemini_response_with_images(
                chat_id, response, reply_to_message_id=message.message_id
            )
        else:
            raw_response_text = response.text

        sources_text = ""
        try:
            if (
                response.candidates
                and response.candidates[0].grounding_metadata
                and response.candidates[0].grounding_metadata.grounding_chunks
            ):
                sources = []
                for i, chunk in enumerate(
                    response.candidates[0].grounding_metadata.grounding_chunks
                ):
                    if (
                        hasattr(chunk, "web")
                        and chunk.web.uri
                        and chunk.web.title
                    ):
                        sources.append(
                            f"{i + 1}. [{chunk.web.title}]({chunk.web.uri})"
                        )
                    elif hasattr(chunk, "web") and chunk.web.uri:
                        sources.append(
                            f"{i + 1}. [{chunk.web.uri}]({chunk.web.uri})"
                        )

                if sources:
                    sources_text = "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + "\n".join(sources)
                    raw_response_text += sources_text
        except (AttributeError, IndexError) as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {e}")

        user_message_buffer[user_id] = []
        user_last_responses[user_id] = raw_response_text

        try:
            bot.delete_message(chat_id, status_msg.message_id)
        except Exception:
            pass

        if not is_image_generation_model(current_model):
            plain_response_text = markdown_to_text(raw_response_text)
            message_parts = split_long_message(plain_response_text)

            for i, part in enumerate(message_parts):
                if i == 0:
                    bot.send_message(
                        chat_id, part, reply_to_message_id=message.message_id
                    )
                else:
                    bot.send_message(chat_id, part)

            if len(message_parts) > 1:
                bot.send_message(
                    chat_id,
                    "–û—Ç–≤–µ—Ç –±—ã–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π.",
                    reply_markup=get_file_download_keyboard(user_id),
                )

    except Exception as e:
        try:
            bot.delete_message(chat_id, status_msg.message_id)
        except Exception:
            pass
        bot.reply_to(
            message,
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e!s}\n\n"
            "–í–∞—à–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —Ñ–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±—É—Ñ–µ—Ä–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±—É—Ñ–µ—Ä–∞.",
            reply_markup=get_main_keyboard(
                user_id,
                user_send_modes,
                user_search_enabled.get(user_id, False),
                user_models.get(user_id, DEFAULT_MODEL),
            ),
        )


@bot.callback_query_handler(
    func=lambda call: call.data.startswith("get_file_")
    or call.data.startswith("get_md_")
)
@ensure_user_started
def handle_get_file(call):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏–µ –∏–Ω–ª–∞–π–Ω –∫–Ω–æ–ø–æ–∫ "–ü–æ–ª—É—á–∏—Ç—å –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞" (.txt –∏–ª–∏ .md)."""

    user_id = int(call.data.split("_")[2])
    file_format = "txt" if call.data.startswith("get_file_") else "md"

    if user_last_responses.get(user_id):
        raw_response = user_last_responses[user_id]

        words = raw_response.split()
        filename = (
            "_".join(words[:3]) + f".{file_format}"
            if len(words) > 0
            else f"response.{file_format}"
        )
        filename = (
            filename.replace("/", "_").replace("\\", "_").replace(":", "_")
        )

        if file_format == "txt":
            file_content = markdown_to_text(raw_response)
            alert_text = "–¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!"
        else:
            file_content = raw_response
            alert_text = "Markdown —Ñ–∞–π–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω!"

        send_text_as_file(
            call.message.chat.id,
            file_content,
            filename,
        )
        bot.answer_callback_query(call.id, text=alert_text)
    else:
        bot.answer_callback_query(
            call.id,
            text="–£ –º–µ–Ω—è –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –≤–∏–¥–µ —Ñ–∞–π–ª–∞.",
        )


@bot.callback_query_handler(func=lambda call: call.data.startswith("model_"))
@ensure_user_started
def handle_model_selection(call):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏."""
    user_id = call.from_user.id
    selected_model = call.data.replace("model_", "")

    PRO_MODEL_NAME = "gemini-2.5-pro"

    if selected_model == PRO_MODEL_NAME and not is_whitelisted(user_id):
        bot.answer_callback_query(
            call.id,
            text="–î–æ—Å—Ç—É–ø –∫ –ø—Ä–æ –º–æ–¥–µ–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /unlock_pro <–ò–º—è —Å–æ–∑–¥–∞—Ç–µ–ª—è –±–æ—Ç–∞>",
        )
        bot.send_message(
            call.message.chat.id,
            "–î–æ—Å—Ç—É–ø –∫ –ø—Ä–æ –º–æ–¥–µ–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É /unlock_pro <–ò–º—è —Å–æ–∑–¥–∞—Ç–µ–ª—è –±–æ—Ç–∞> –¥–ª—è —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏.",
            reply_markup=get_main_keyboard(
                user_id,
                user_send_modes,
                user_search_enabled.get(user_id, False),
                user_models.get(user_id, DEFAULT_MODEL),
            ),
        )
        return

    user_models[user_id] = selected_model

    user_chats[user_id] = client.chats.create(model=user_models[user_id])
    user_last_responses[user_id] = None
    user_files_context[user_id] = []
    user_message_buffer[user_id] = []

    bot.answer_callback_query(call.id)
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=(
            f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {get_model_alias(selected_model)}\n\n"
            f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω."
        ),
    )

    search_enabled = user_search_enabled.get(user_id, False)
    current_model = user_models.get(user_id, DEFAULT_MODEL)
    bot.send_message(
        call.message.chat.id,
        "–ú–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥.",
        reply_markup=get_main_keyboard(
            user_id, user_send_modes, search_enabled, current_model
        ),
    )


@bot.message_handler(content_types=["document"])
@ensure_user_started
def handle_document(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç."""
    user_id = message.from_user.id
    chat_id = message.chat.id

    doc_mime_type = message.document.mime_type
    if doc_mime_type in SUPPORTED_MIME_TYPES:
        try:
            bot.send_chat_action(chat_id, "upload_document")
            file_info = bot.get_file(message.document.file_id)

            if file_info.file_size > MAX_FILE_SIZE_MB * 1024 * 1024:
                bot.reply_to(
                    message,
                    f"‚ùå –§–∞–π–ª '{message.document.file_name}' —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π "
                    f"(> {MAX_FILE_SIZE_MB} –ú–ë). –Ø –º–æ–≥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã —Ä–∞–∑–º–µ—Ä–æ–º –¥–æ {MAX_FILE_SIZE_MB} –ú–ë.",
                    reply_markup=get_main_keyboard(
                        user_id,
                        user_send_modes,
                        user_search_enabled.get(user_id, False),
                        user_models.get(user_id, DEFAULT_MODEL),
                    ),
                )
                return

            downloaded_file = bot.download_file(file_info.file_path)
            pdf_bytes = downloaded_file
            filename = message.document.file_name
            caption = message.caption or ""

            file_data = {
                "mime_type": doc_mime_type,
                "data": pdf_bytes,
                "filename": filename,
                "caption": caption,
            }

            if user_id not in user_files_context:
                user_files_context[user_id] = []
            user_files_context[user_id].append(file_data)
            context_count = len(user_files_context[user_id])

            current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)

            if current_mode == SEND_MODE_MANUAL:
                if user_id not in user_message_buffer:
                    user_message_buffer[user_id] = []
                user_message_buffer[user_id].append(
                    {**file_data, "type": "document"}
                )
                buffer_count = len(user_message_buffer[user_id])
                file_type_short = doc_mime_type.split("/")[-1].upper()
                bot.reply_to(
                    message,
                    f"üìÑ –§–∞–π–ª '{filename}' ({file_type_short}) –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±—É—Ñ–µ—Ä ({buffer_count} —à—Ç.). "
                    + ("–ü–æ–¥–ø–∏—Å—å —Ç–∞–∫–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞.\n" if caption else "\n")
                    + f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ: {context_count}.\n"
                    + "–ù–∞–∂–º–∏—Ç–µ '–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å—ë', –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã.",
                    reply_markup=get_main_keyboard(
                        user_id,
                        user_send_modes,
                        user_search_enabled.get(user_id, False),
                        user_models.get(user_id, DEFAULT_MODEL),
                    ),
                )
            else:
                file_type_short = doc_mime_type.split("/")[-1].upper()
                bot.reply_to(
                    message,
                    f"‚úÖ –§–∞–π–ª '{filename}' ({file_type_short}) –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç (–≤—Å–µ–≥–æ: {context_count}). "
                    "–û–Ω –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º –∑–∞–ø—Ä–æ—Å–µ.",
                    reply_markup=get_main_keyboard(
                        user_id,
                        user_send_modes,
                        user_search_enabled.get(user_id, False),
                        user_models.get(user_id, DEFAULT_MODEL),
                    ),
                )

        except Exception as e:
            bot.reply_to(
                message,
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª '{message.document.file_name}': {e!s}",
                reply_markup=get_main_keyboard(
                    user_id,
                    user_send_modes,
                    user_search_enabled.get(user_id, False),
                    user_models.get(user_id, DEFAULT_MODEL),
                ),
            )
    else:
        supported_types_str = ", ".join(
            sorted(
                [
                    t.split("/")[-1].upper()
                    for t in SUPPORTED_MIME_TYPES
                    if not t.startswith("application/x")
                ]
            )
        )
        bot.reply_to(
            message,
            f"–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–æ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ ({doc_mime_type}). \n–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã: {supported_types_str}",
            reply_markup=get_main_keyboard(
                user_id,
                user_send_modes,
                user_search_enabled.get(user_id, False),
                user_models.get(user_id, DEFAULT_MODEL),
            ),
        )


@bot.message_handler(content_types=["photo"])
@ensure_user_started
def handle_photo(message):
    user_id = message.from_user.id
    chat_id = message.chat.id

    current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)

    file_id = message.photo[-1].file_id
    caption = message.caption if message.caption else ""
    if current_mode == SEND_MODE_MANUAL:
        try:
            bot.send_chat_action(chat_id, "typing")
            image_stream = download_telegram_image(file_id)
            img = Image.open(image_stream)

            if user_id not in user_message_buffer:
                user_message_buffer[user_id] = []
            user_message_buffer[user_id].append(
                {"type": "photo", "image": img, "caption": caption}
            )
            buffer_count = len(user_message_buffer[user_id])
            bot.reply_to(
                message,
                f"–§–æ—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±—É—Ñ–µ—Ä ({buffer_count} —à—Ç.). "
                + ("–ü–æ–¥–ø–∏—Å—å —Ç–∞–∫–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞.\n" if caption else "\n")
                + "–ù–∞–∂–º–∏—Ç–µ '–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å—ë', –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã.",
                reply_markup=get_main_keyboard(
                    user_id,
                    user_send_modes,
                    user_search_enabled.get(user_id, False),
                    user_models.get(user_id, DEFAULT_MODEL),
                ),
            )
        except Exception as e:
            bot.reply_to(
                message,
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ –≤ –±—É—Ñ–µ—Ä: {e!s}",
                reply_markup=get_main_keyboard(
                    user_id,
                    user_send_modes,
                    user_search_enabled.get(user_id, False),
                    user_models.get(user_id, DEFAULT_MODEL),
                ),
            )
        return

    if user_id not in user_chats:
        try:

            user_chats[user_id] = client.chats.create(
                model=user_models[user_id]
            )
            user_last_responses[user_id] = None
        except Exception as e:
            bot.reply_to(
                message,
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∞—Ç –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Ñ–æ—Ç–æ: {e!s}",
                reply_markup=get_main_keyboard(
                    user_id,
                    user_send_modes,
                    user_search_enabled.get(user_id, False),
                    user_models.get(user_id, DEFAULT_MODEL),
                ),
            )
            return

    bot.send_chat_action(chat_id, "typing")
    try:
        image_stream = download_telegram_image(file_id)
        img = Image.open(image_stream)

        api_message_parts = []

        if caption:
            api_message_parts.append(caption)
        api_message_parts.append(img)

        chat_session = user_chats[user_id]

        current_model = user_models.get(user_id, DEFAULT_MODEL)
        if is_image_generation_model(current_model):
            gemini_config = GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"]
            )
            response = chat_session.send_message(
                message=api_message_parts, config=gemini_config
            )
        else:
            response = chat_session.send_message(message=api_message_parts)

        if is_image_generation_model(current_model):
            raw_response_text = send_gemini_response_with_images(
                chat_id, response, reply_to_message_id=message.message_id
            )
        else:
            raw_response_text = response.text

        user_last_responses[user_id] = raw_response_text

        if not is_image_generation_model(current_model):
            plain_response_text = markdown_to_text(raw_response_text)
            message_parts = split_long_message(plain_response_text)

            for i, part in enumerate(message_parts):
                if i == 0:
                    bot.reply_to(message, part)
                else:
                    bot.send_message(chat_id, part)

            if len(message_parts) > 1:
                bot.send_message(
                    chat_id,
                    "–û—Ç–≤–µ—Ç –±—ã–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π.",
                    reply_markup=get_file_download_keyboard(user_id),
                )

    except Exception as e:
        bot.reply_to(
            message,
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({user_models.get(user_id, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}): {e!s}\n\n"
            "–í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç.",
            reply_markup=get_main_keyboard(
                user_id,
                user_send_modes,
                user_search_enabled.get(user_id, False),
                user_models.get(user_id, DEFAULT_MODEL),
            ),
        )


@bot.message_handler(
    func=lambda message: message.text
    and message.text.startswith("/")
    and message.text.split(" ", 1)[0][1:] in QUICK_TOOLS_CONFIG
)
@ensure_user_started
def handle_quick_tool_command(message):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –±—ã—Å—Ç—Ä—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä., /translate, /prompt)."""
    chat_id = message.chat.id
    command_with_slash = message.text.split(" ", 1)[0]
    command = command_with_slash[1:]
    user_query = (
        message.text.split(" ", 1)[1].strip() if " " in message.text else ""
    )

    if not user_query:
        bot.reply_to(
            message,
            f"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã {command_with_slash}.\n"
            f"–ù–∞–ø—Ä–∏–º–µ—Ä: `{command_with_slash} –≤–∞—à —Ç–µ–∫—Å—Ç –∑–¥–µ—Å—å`",
            parse_mode="Markdown",
        )
        return

    tool_config = QUICK_TOOLS_CONFIG[command]
    system_instruction = tool_config["system_instruction"]
    model_to_use = tool_config.get("model", DEFAULT_MODEL)
    thinking_budget = tool_config.get("thinking_budget", None)

    bot.send_chat_action(chat_id, "typing")
    status_msg = bot.reply_to(
        message, f"–í—ã–ø–æ–ª–Ω—è—é –∫–æ–º–∞–Ω–¥—É `{command_with_slash}`..."
    )

    if len(user_query) > 4000:
        bot.reply_to(
            message,
            f"–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è –∫–æ–º–∞–Ω–¥—ã {command_with_slash}. –ú–∞–∫—Å–∏–º—É–º 4000 —Å–∏–º–≤–æ–ª–æ–≤.",
        )
        return

    try:
        config_kwargs = {"system_instruction": system_instruction}
        if model_to_use == "gemini-2.5-flash" and thinking_budget is not None:
            config_kwargs["thinking_config"] = genai_types.ThinkingConfig(
                thinking_budget=thinking_budget
            )

        if is_image_generation_model(model_to_use):
            config_kwargs["response_modalities"] = ["TEXT", "IMAGE"]

        response = client.models.generate_content(
            model=model_to_use,
            contents=user_query,
            config=genai_types.GenerateContentConfig(**config_kwargs),
        )

        if is_image_generation_model(model_to_use):
            raw_response_text = send_gemini_response_with_images(
                chat_id, response, reply_to_message_id=message.message_id
            )
        else:
            raw_response_text = response.text

        if command in ["todo", "markdown", "dayplanner"]:
            words = user_query.split()
            filename_base = "_".join(words[:3]) if len(words) > 0 else command
            filename = f"{filename_base}_{command}.md"
            filename = (
                filename.replace("/", "_").replace("\\", "_").replace(":", "_")
            )
            send_text_as_file(chat_id, raw_response_text, filename)

        try:
            bot.delete_message(chat_id, status_msg.message_id)
        except Exception:
            pass

        if not is_image_generation_model(model_to_use):
            plain_response_text = markdown_to_text(raw_response_text)
            message_parts = split_long_message(plain_response_text)

            for i, part in enumerate(message_parts):
                if i == 0:
                    bot.reply_to(message, part)
                else:
                    bot.send_message(chat_id, part)

    except Exception as e:
        try:
            bot.delete_message(chat_id, status_msg.message_id)
        except Exception:
            pass
        print(f"Error in quick tool command '{command}': {e}")
        bot.reply_to(
            message,
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã `{command_with_slash}`: {e!s}",
        )


@bot.message_handler(func=lambda message: True)
@ensure_user_started
def handle_message(message):
    user_id = message.from_user.id
    chat_id = message.chat.id

    current_mode = user_send_modes.get(user_id, SEND_MODE_IMMEDIATE)

    if current_mode == SEND_MODE_MANUAL:
        if user_id not in user_message_buffer:
            user_message_buffer[user_id] = []
        user_message_buffer[user_id].append(
            {"type": "text", "content": message.text}
        )
        buffer_count = len(user_message_buffer[user_id])
        bot.reply_to(
            message,
            f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –±—É—Ñ–µ—Ä ({buffer_count} —à—Ç.). –ù–∞–∂–º–∏—Ç–µ '–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å—ë', –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã.",
        )
        return

    bot.send_chat_action(message.chat.id, "typing")

    try:

        api_message_parts = []

        files_in_context = user_files_context.get(user_id, [])
        if files_in_context:
            bot.send_message(
                chat_id,
                f"üìé –ò—Å–ø–æ–ª—å–∑—É—é {len(files_in_context)} —Ñ–∞–π–ª(–∞/–æ–≤) –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...",
            )
            for file_info in files_in_context:

                if file_info["caption"]:
                    api_message_parts.append(file_info["caption"])

                try:
                    api_message_parts.append(
                        genai_types.Part.from_bytes(
                            mime_type=file_info["mime_type"],
                            data=file_info["data"],
                        )
                    )

                    api_message_parts.append(
                        f"(–§–∞–π–ª: {file_info['filename']})"
                    )
                except Exception as file_err:
                    bot.send_message(
                        chat_id,
                        f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª '{file_info['filename']}' –≤ –∑–∞–ø—Ä–æ—Å: {file_err}",
                    )

        api_message_parts.append(message.text)

        if user_id not in user_chats:

            try:
                user_chats[user_id] = client.chats.create(
                    model=user_models[user_id]
                )
            except Exception as e:
                bot.reply_to(
                    message,
                    f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —á–∞—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π: {e!s}",
                )
                return

        current_model = user_models.get(user_id, DEFAULT_MODEL)
        if is_image_generation_model(current_model):
            gemini_config = GenerateContentConfig(
                response_modalities=["TEXT", "IMAGE"]
            )
        else:
            tools = [Tool(url_context=genai_types.UrlContext())]
            if user_search_enabled.get(user_id, False):
                tools.append(Tool(google_search=GoogleSearch()))
            gemini_config = GenerateContentConfig(tools=tools)

        response = user_chats[user_id].send_message(
            message=api_message_parts, config=gemini_config
        )

        current_model = user_models.get(user_id, DEFAULT_MODEL)
        if is_image_generation_model(current_model):
            raw_response_text = send_gemini_response_with_images(
                message.chat.id,
                response,
                reply_to_message_id=message.message_id,
            )
        else:
            raw_response_text = response.text

        sources_text = ""
        try:
            if (
                response.candidates
                and response.candidates[0].grounding_metadata
                and response.candidates[0].grounding_metadata.grounding_chunks
            ):
                sources = []
                for i, chunk in enumerate(
                    response.candidates[0].grounding_metadata.grounding_chunks
                ):
                    if (
                        hasattr(chunk, "web")
                        and chunk.web.uri
                        and chunk.web.title
                    ):
                        sources.append(
                            f"{i + 1}. [{chunk.web.title}]({chunk.web.uri})"
                        )
                    elif hasattr(chunk, "web") and chunk.web.uri:
                        sources.append(
                            f"{i + 1}. [{chunk.web.uri}]({chunk.web.uri})"
                        )

                if sources:
                    sources_text = "\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + "\n".join(sources)
                    raw_response_text += sources_text
        except (AttributeError, IndexError) as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {e}")

        user_last_responses[user_id] = raw_response_text

        if not is_image_generation_model(current_model):
            plain_response_text = (
                markdown_to_text(response.text) + sources_text
            )
            message_parts = split_long_message(plain_response_text)

            for i, part in enumerate(message_parts):
                if i == 0:
                    bot.reply_to(message, part)
                else:
                    bot.send_message(message.chat.id, part)

            if len(message_parts) > 1:
                bot.send_message(
                    message.chat.id,
                    "–û—Ç–≤–µ—Ç –±—ã–ª —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π.",
                    reply_markup=get_file_download_keyboard(user_id),
                )
    except Exception as e:
        bot.reply_to(
            message,
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e!s}\n\n–í–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç "
            f"–ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç.",
            reply_markup=get_main_keyboard(
                user_id,
                user_send_modes,
                user_search_enabled.get(user_id, False),
                user_models.get(user_id, DEFAULT_MODEL),
            ),
        )


if __name__ == "__main__":
    load_whitelist()
    bot.polling(none_stop=True)
